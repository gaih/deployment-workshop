{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an image and dockerizing an app:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say you have a hello-world flask app called \"app.py\". We first need to have a dockerfile. An example would be:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "               FROM python:3.8\n",
    "                \n",
    "               #set a directory for the app\n",
    "               WORKDIR /usr/src/app\n",
    "                \n",
    "               #copy all the files in the current directory to the container\n",
    "               COPY ..\n",
    "                \n",
    "               #install dependencies\n",
    "               RUN pip install -r requirements.txt\n",
    "                \n",
    "               #run the command\n",
    "               CMD [\"python\", \"app.py\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It pulls the python3 image to be able to run the app with python3, it is the parent image, the base. The requirements file would have the version of flask you are using. So that whenever someone is using this image they would also use that version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we create our dockerfile, we can build our image by running the command:\n",
    "* docker build -t (image name) .\n",
    "\n",
    "After that, we can run the image as we did on the hello-world image before.\n",
    "* docker run -d -p 5000:5000 (username)/(directory which has the dockerfile)\n",
    "\n",
    "-p publishes a container's port to the host. We used port 5000 for the server inside the container and this was exposed to port 5000, now we can acces our flask app through localhost:5000. http://127.0.0.1:5000/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Docker Compose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compose is a tool for defining and running multi-container Docker applications. With Compose, you use a YAML file to configure your application’s services. Then, with a single command, you create and start all the services from your configuration.\n",
    "\n",
    "Using Compose is basically a three-step process:\n",
    "\n",
    "* Define your app’s environment with a Dockerfile so it can be reproduced anywhere.\n",
    "\n",
    "* Define the services that make up your app in docker-compose.yml so they can be run together in an isolated environment.\n",
    "\n",
    "* Run docker-compose up and Compose starts and runs your entire app."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Container Orchestration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In environments where we have bunch of containers running, we need to be aware of the situation of each container. New containers might be added, some might be removed, there might be a lot happening in this environment. There must be some kind of a system to keep track of each container, check whether they're alive or not. Also, container orchestration is used for automating several tasks, such as: load balancing, health montioring, scaling for the necessary need (saves a lot of money), allocation of resources among containers... This can be done by several orchestrator tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![8281.1530784485.png](https://devopedia.org/images/article/37/8281.1530784485.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kubernetes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kubernetes is a system for automating deployment, scaling, and management of containerized applications. It groups containers that make up an application into logical units for easy management and discovery.\n",
    "\n",
    "Kubernetes leverages the simplicity of Platform as a Service (PaaS) when used on the Cloud. It utilises the flexibility of Infrastructure as a Service (IaaS) and enables portability and simplified scaling; empowering infrastructure vendors to provision robust Software as a Service (Saas) business models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kubernetes is not just an orchestration system; it eliminates the need for orchestration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Demystifying-containers_image2.png](https://cloudblogs.microsoft.com/uploads/prod/sites/37/2019/07/Demystifying-containers_image2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kubernetes manages multiple containers, one application or service can be housed in a container or its image. Fixed container images can be created at build time rather than deployment time, as each application does not need to be coordinated within the rest of the application stack and is not coupled via the production infrastructure environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The creation of container images at the moment of production or release ensures a continuous environment from development to production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Kubernetes Master?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It controls the scheduling and deployment of applications. It communicates with nodes through the Kubernetes API server. It assigns nodes to pods depending on the resource and policy constraints you’ve defined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a cluster?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a set of node with at least one master node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a node?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A node is a common term for virtual machines and/or bare-metal servers that Kubernetes manages. There are two types of nodes, Master node and Worker nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a pod?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Pod is a collection of one or more containers that are used in each respective node. All containers in the Pod share the IP address, IPC, hostname, and additional resources. In addition, each Pod executes at least one Kubelet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a Kubelet?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kubelet is an agent of the master. This is executed on each node and is responsible for the connection between master and node. It also sends the information about a node's health back to the master node, so that the health-check feature can take place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the health-check and self-repair feature?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the advantages of Kubernetes is that you can be rest assured knowiing that your nodes will be up and running. Faulty node gets reopened. Whenever a node fails, the kubelet sends this information to the master node, and the contaiiners within gets redistributed, and if a node doesn't respond to a health-check, it autoomatically gets restarted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is kube-proxy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a proxy service which runs on each node and helps in making services available to the external host. It helps in forwarding the request to correct containers. It makes sure that the networking environment is accessible, and it is isolated as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![docker-workflow-ci-cd-aks.png](https://docs.microsoft.com/tr-tr/dotnet/architecture/containerized-lifecycle/docker-devops-workflow/media/docker-workflow-ci-cd-aks.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New innovations running on the cloud are light-weight. Time is of the essence and fast software delivery is important. Whether pushing the commit to deploy new versions or reverting back after a failure, automated processes save time, maintain quality, keep consistency. These are important for a team to work together and move forward."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
